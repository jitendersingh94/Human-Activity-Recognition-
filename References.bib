% This file was created with
% Encoding: 


@article{1dataset,
  title={A Public Domain Dataset for Human Activity Recognition Using Smartphones, 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
  author={Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz},
  journal={ESANN 2013},
  month={Apr.},
  year={2013},
}


@inproceedings{2leap,
  title={Leap Motion Technology in Learning},
  author={P{\u{a}}v{\u{a}}loiu, Ionel-Bujorel},
  booktitle={Conference Paper. EpSBS, Bukure{\v{s}}t'},
  year={2016}
}

@article{3poppe2010survey,
  title={A survey on vision-based human action recognition},
  author={Poppe, Ronald},
  journal={Image and vision computing},
  volume={28},
  number={6},
  pages={976--990},
  year={2010},
  publisher={Elsevier}
}

@article{4Jaouedi2016HumanAR,
  title={Human action recognition to human behavior analysis},
  author={Neziha Jaouedi and Noureddine Boujnah and Oumayma Htiwich and M. Bouhlel},
  journal={2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)},
  year={2016},
  pages={263-266}
}

@article{5kwapisz2011activity,
  title={Activity recognition using cell phone accelerometers},
  author={Kwapisz, Jennifer R and Weiss, Gary M and Moore, Samuel A},
  journal={ACM SigKDD Explorations Newsletter},
  volume={12},
  number={2},
  pages={74--82},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inproceedings{6kwapisz2010cell,
  title={Cell phone-based biometric identification},
  author={Kwapisz, Jennifer R and Weiss, Gary M and Moore, Samuel A},
  booktitle={2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS)},
  pages={1--7},
  year={2010},
  organization={IEEE}
}

@inproceedings{7casale2011human,
  title={Human activity recognition from accelerometer data using a wearable device},
  author={Casale, Pierluigi and Pujol, Oriol and Radeva, Petia},
  booktitle={Iberian conference on pattern recognition and image analysis},
  pages={289--296},
  year={2011},
  organization={Springer}
}

@inproceedings{8krishnan2008real,
  title={Real time human activity recognition using tri-axial accelerometers},
  author={Krishnan, Narayanan C and Colbry, Dirk and Juillard, Colin and Panchanathan, Sethuraman},
  booktitle={Sensors, signals and information processing workshop},
  pages={3337--3340},
  year={2008}
}

@article{9ranasinghe2016review,
  title={A review on applications of activity recognition systems with regard to performance and evaluation},
  author={Ranasinghe, Suneth and Al Machot, Fadi and Mayr, Heinrich C},
  journal={International Journal of Distributed Sensor Networks},
  volume={12},
  number={8},
  pages={1550147716665520},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{10menschner2011reaching,
  title={Reaching into patients’ homes--participatory designed AAL services},
  author={Menschner, Philipp and Prinz, Andreas and Koene, Philip and K{\"o}bler, Felix and Altmann, Matthias and Krcmar, Helmut and Leimeister, Jan Marco},
  journal={Electronic Markets},
  volume={21},
  number={1},
  pages={63--76},
  year={2011},
  publisher={Springer}
}

@article{11demiris2008senior,
  title={Senior residents' perceived need of and preferences for" smart home" sensor technologies},
  author={Demiris, George and Hensel, Brian K and Skubic, Marjorie and Rantz, Marilyn},
  journal={International journal of technology assessment in health care},
  volume={24},
  number={1},
  pages={120},
  year={2008},
  publisher={Citeseer}
}

@article{12gannapathy2013zigbee,
  title={Zigbee-Based Smart Fall Detection and Notification System with Wearable Sensor (e-SAFE)},
  author={Gannapathy, Vigneswara Rao and Ibrahim, AFBT and Zakaria, Zahriladha Bin and Othman, Abdul Rani Bin and Latiff, Anas Abdul},
  journal={Int. J. Res. Eng. Technol},
  volume={2},
  pages={337--344},
  year={2013}
}

@inproceedings{13ogbuabor2018human,
  title={Human activity recognition for healthcare using smartphones},
  author={Ogbuabor, Godwin and La, Robert},
  booktitle={Proceedings of the 2018 10th international conference on machine learning and computing},
  pages={41--46},
  year={2018}
}

@article{14aggarwal2011human,
  title={Human activity analysis: A review},
  author={Aggarwal, Jake K and Ryoo, Michael S},
  journal={ACM Computing Surveys (CSUR)},
  volume={43},
  number={3},
  pages={1--43},
  year={2011},
  publisher={Acm New York, NY, USA}
}

@inproceedings{15yao2017deepsense,
  title={Deepsense: A unified deep learning framework for time-series mobile sensing data processing},
  author={Yao, Shuochao and Hu, Shaohan and Zhao, Yiran and Zhang, Aston and Abdelzaher, Tarek},
  booktitle={Proceedings of the 26th International Conference on World Wide Web},
  pages={351--360},
  year={2017}
}

@article{16ordonez2016deep,
  title={Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition},
  author={Ord{\'o}{\~n}ez, Francisco Javier and Roggen, Daniel},
  journal={Sensors},
  volume={16},
  number={1},
  pages={115},
  year={2016},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{17hammerla2016deep,
  title={Deep, convolutional, and recurrent models for human activity recognition using wearables},
  author={Hammerla, Nils Y and Halloran, Shane and Pl{\"o}tz, Thomas},
  journal={arXiv preprint arXiv:1604.08880},
  year={2016}
}

@article{18mcmahan2016federated,
  title={Federated learning of deep networks using model averaging},
  author={McMahan, H Brendan and Moore, Eider and Ramage, Daniel and y Arcas, Blaise Ag{\"u}era},
  journal={arXiv preprint arXiv:1602.05629},
  year={2016},
  publisher={Technical report}
}

@article{19zaki2020logistic,
  title={Logistic regression based human activities recognition},
  author={Zaki, Zunash and Shah, Muhammad Arif and Wakil, Karzan and Sher, Falak},
  journal={J. Mech. Contin. Math. Sci},
  year={2020}
}

@inproceedings{20feng2015random,
  title={A Random Forest-based ensemble method for activity recognition},
  author={Feng, Zengtao and Mo, Lingfei and Li, Meng},
  booktitle={2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
  pages={5074--5077},
  year={2015},
  organization={IEEE}
}

@inproceedings{21fan2013human,
  title={Human activity recognition model based on decision tree},
  author={Fan, Lin and Wang, Zhongmin and Wang, Hai},
  booktitle={2013 International Conference on Advanced Cloud and Big Data},
  pages={64--68},
  year={2013},
  organization={IEEE}
}

@article{22chen2019towards,
  title={Towards accurate prediction for high-dimensional and highly-variable cloud workloads with deep learning},
  author={Chen, Zheyi and Hu, Jia and Min, Geyong and Zomaya, Albert Y and El-Ghazawi, Tarek},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={31},
  number={4},
  pages={923--934},
  year={2019},
  publisher={IEEE}
}

@article{23gupta2014feature,
  title={Feature selection and activity recognition system using a single triaxial accelerometer},
  author={Gupta, Piyush and Dallas, Tim},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={61},
  number={6},
  pages={1780--1786},
  year={2014},
  publisher={IEEE}
}

@article{24lee2002activity,
  title={Activity and location recognition using wearable sensors},
  author={Lee, Seon-Woo and Mase, Kenji},
  journal={IEEE pervasive computing},
  volume={1},
  number={3},
  pages={24--32},
  year={2002},
  publisher={IEEE}
}

@inproceedings{25mantyjarvi2001recognizing,
  title={Recognizing human motion with multiple acceleration sensors},
  author={Mantyjarvi, Jani and Himberg, Johan and Seppanen, Tapio},
  booktitle={2001 ieee international conference on systems, man and cybernetics. e-systems and e-man for cybernetics in cyberspace (cat. no. 01ch37236)},
  volume={2},
  pages={747--752},
  year={2001},
  organization={IEEE}
}









@article{10.1145/1964897.1964918,
author = {Kwapisz, Jennifer R. and Weiss, Gary M. and Moore, Samuel A.},
title = {Activity Recognition Using Cell Phone Accelerometers},
year = {2011},
issue_date = {December 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/1964897.1964918},
doi = {10.1145/1964897.1964918},
abstract = {Mobile devices are becoming increasingly sophisticated and the latest generation of smart cell phones now incorporates many diverse and powerful sensors. These sensors include GPS sensors, vision sensors (i.e., cameras), audio sensors (i.e., microphones), light sensors, temperature sensors, direction sensors (i.e., magnetic compasses), and acceleration sensors (i.e., accelerometers). The availability of these sensors in mass-marketed communication devices creates exciting new opportunities for data mining and data mining applications. In this paper we describe and evaluate a system that uses phone-based accelerometers to perform activity recognition, a task which involves identifying the physical activity a user is performing. To implement our system we collected labeled accelerometer data from twenty-nine users as they performed daily activities such as walking, jogging, climbing stairs, sitting, and standing, and then aggregated this time series data into examples that summarize the user activity over 10- second intervals. We then used the resulting training data to induce a predictive model for activity recognition. This work is significant because the activity recognition model permits us to gain useful knowledge about the habits of millions of users passively---just by having them carry cell phones in their pockets. Our work has a wide range of applications, including automatic customization of the mobile device's behavior based upon a user's activity (e.g., sending calls directly to voicemail if a user is jogging) and generating a daily/weekly activity profile to determine if a user (perhaps an obese child) is performing a healthy amount of exercise.},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {74–82},
numpages = {9},
keywords = {induction, sensors, accelerometer, cell phone, activity recognition, sensor mining}
}

@INPROCEEDINGS{5634532,
  author={Kwapisz, Jennifer R. and Weiss, Gary M. and Moore, Samuel A.},
  booktitle={2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS)}, 
  title={Cell phone-based biometric identification}, 
  year={2010},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/BTAS.2010.5634532}}
  
  @article{doi:10.1177/1550147716665520,
author = {Suneth Ranasinghe and Fadi Al Machot and Heinrich C Mayr},
title ={A review on applications of activity recognition systems with regard to performance and evaluation},
journal = {International Journal of Distributed Sensor Networks},
volume = {12},
number = {8},
pages = {1550147716665520},
year = {2016},
doi = {10.1177/1550147716665520},

URL = { 
        https://doi.org/10.1177/1550147716665520
    
},
eprint = { 
        https://doi.org/10.1177/1550147716665520
    
}
,
    abstract = { Activity recognition systems are a large field of research and development, currently with a focus on advanced machine learning algorithms, innovations in the field of hardware architecture, and on decreasing the costs of monitoring while increasing safety. This article concentrates on the applications of activity recognition systems and surveys their state of the art. We categorize such applications into active and assisted living systems for smart homes, healthcare monitoring applications, monitoring and surveillance systems for indoor and outdoor activities, and tele-immersion applications. Within these categories, the applications are classified according to the methodology used for recognizing human behavior, namely, based on visual, non-visual, and multimodal sensor technology. We provide an overview of these applications and discuss the advantages and limitations of each approach. Additionally, we illustrate public data sets that are designed for the evaluation of such recognition systems. The article concludes with a comparison of the existing methodologies which, when applied to real-world scenarios, allow to formulate research questions for future approaches. }
}

@inproceedings{10.1145/3195106.3195157,
author = {Ogbuabor, Godwin and La, Robert},
title = {Human Activity Recognition for Healthcare Using Smartphones},
year = {2018},
isbn = {9781450363532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195106.3195157},
doi = {10.1145/3195106.3195157},
abstract = {The healthcare benefits associated with regular physical activity monitoring and recognition has been considered in several research studies. Solid evidence shows that regular monitoring and recognition of physical activity can potentially assist to manage and reduce the risk of many diseases such as obesity, cardiovascular and diabetes. A few studies have been carried out in order to develop effective human activity recognition system using smartphone. However, understanding the role of each sensor embedded in the smartphone for activity recognition is essential and need to be investigated. Due to the recent outstanding performance of artificial neural networks in human activity recognition, this work aims to investigate the role of gyroscope and accelerometer sensors and its combination for automatic human activity detection, analysis and recognition using artificial neural networks. The experimental result on the publicly available dataset indicates that each of the sensors can be used for human activity recognition separately. However, accelerometer sensor data performed better than gyroscope sensor data with classification accuracy of 92%. Combining accelerometer and gyroscope performed better than when used individually with an accuracy of 95%.},
booktitle = {Proceedings of the 2018 10th International Conference on Machine Learning and Computing},
pages = {41–46},
numpages = {6},
keywords = {Artificial Neural Networks, Gyroscope sensor, Healthcare, Smartphone, Accelerometer sensor},
location = {Macau, China},
series = {ICMLC 2018}
}

@article{10.1145/1922649.1922653,
author = {Aggarwal, J.K. and Ryoo, M.S.},
title = {Human Activity Analysis: A Review},
year = {2011},
issue_date = {April 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/1922649.1922653},
doi = {10.1145/1922649.1922653},
abstract = {Human activity recognition is an important area of computer vision research. Its applications include surveillance systems, patient monitoring systems, and a variety of systems that involve interactions between persons and electronic devices such as human-computer interfaces. Most of these applications require an automated recognition of high-level activities, composed of multiple simple (or atomic) actions of persons. This article provides a detailed overview of various state-of-the-art research papers on human activity recognition. We discuss both the methodologies developed for simple human actions and those for high-level activities. An approach-based taxonomy is chosen that compares the advantages and limitations of each approach.Recognition methodologies for an analysis of the simple actions of a single person are first presented in the article. Space-time volume approaches and sequential approaches that represent and recognize activities directly from input images are discussed. Next, hierarchical recognition methodologies for high-level activities are presented and compared. Statistical approaches, syntactic approaches, and description-based approaches for hierarchical recognition are discussed in the article. In addition, we further discuss the papers on the recognition of human-object interactions and group activities. Public datasets designed for the evaluation of the recognition methodologies are illustrated in our article as well, comparing the methodologies' performances. This review will provide the impetus for future research in more productive areas.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {16},
numpages = {43},
keywords = {video recognition, Computer vision, human activity recognition, event detection, activity analysis}
}

@article{DBLP:journals/corr/YaoHZZA16,
  author    = {Shuochao Yao and
               Shaohan Hu and
               Yiran Zhao and
               Aston Zhang and
               Tarek F. Abdelzaher},
  title     = {DeepSense: {A} Unified Deep Learning Framework for Time-Series Mobile
               Sensing Data Processing},
  journal   = {CoRR},
  volume    = {abs/1611.01942},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01942},
  archivePrefix = {arXiv},
  eprint    = {1611.01942},
  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YaoHZZA16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@Article{s16010115,
AUTHOR = {Ordóñez, Francisco Javier and Roggen, Daniel},
TITLE = {Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {1},
ARTICLE-NUMBER = {115},
URL = {https://www.mdpi.com/1424-8220/16/1/115},
PubMedID = {26797612},
ISSN = {1424-8220},
ABSTRACT = {Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4% on average; outperforming some of the previous reported results by up to 9%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters’ influence on performance to provide insights about their optimisation.},
DOI = {10.3390/s16010115}
}
